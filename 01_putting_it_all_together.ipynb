{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PyTorch and matplotlib\n",
    "import torch\n",
    "from torch import nn # nn contain all of PT building blocks\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Py version\n",
    "torch.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Device-agnostic code. \n",
    "Will use GPU if available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create toy data using linear regression formula y = weight * X + bias\n",
    "weight = 0.7\n",
    "bias = 0.3\n",
    "\n",
    "# set range of values\n",
    "start = 0\n",
    "end = 1\n",
    "step = 0.02\n",
    "\n",
    "# Create X and y (features and labels)\n",
    "X = torch.arange(start, end, step).unsqueeze(dim=1)\n",
    "y = weight * X + bias\n",
    "\n",
    "X[:10], y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "train_split = int(0.8 * len(X))\n",
    "X_train, y_train = X[:train_split], y[:train_split]\n",
    "X_test, y_test = X[train_split:], y[train_split:]\n",
    "len(X_train), len(y_train), len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(train_data=X_train,\n",
    "                     train_labels=y_train,\n",
    "                     test_data=X_test,\n",
    "                     test_labels=y_test,\n",
    "                     predictions=None):\n",
    "    \"\"\"\n",
    "    Plots training data, test data and compares predictions.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10,7))\n",
    "\n",
    "    # Plot training data in blue\n",
    "    plt.scatter(train_data, train_labels, c=\"b\", s=4, label=\"Training data\")\n",
    "\n",
    "    # Plot test data in green\n",
    "    plt.scatter(test_data, test_labels, c=\"g\", s=4, label=\"Testing data\")\n",
    "\n",
    "    # if predictions\n",
    "    if predictions is not None:\n",
    "        # Plot the predictions if they exist\n",
    "        plt.scatter(test_data, predictions, c=\"r\", s=4, label=\"Predictions\")\n",
    "    \n",
    "    plt.legend(prop={\"size\": 14});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subclass linear model\n",
    "class LinearRegressionModelWLayers(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # using nn.Linear() for model params\n",
    "        self.linear_layer = nn.Linear(in_features=1,\n",
    "                                      out_features=1)\n",
    "        \n",
    "        \n",
    "        \n",
    "    # forward method to define the computation in model\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.linear_layer(x)\n",
    "    \n",
    "torch.manual_seed(42)\n",
    "model_1 = LinearRegressionModelWLayers()\n",
    "model_1, model_1.state_dict()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check model current device\n",
    "next(model_1.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.to(device)\n",
    "next(model_1.parameters()).device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "requires:\n",
    "* Loss function\n",
    "* Optimizer\n",
    "* Training Loop\n",
    "* Testing Loop\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup loss function\n",
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "# Setup optimizer\n",
    "optimizer = torch.optim.SGD(params=model_1.parameters(),\n",
    "                            lr=0.01 # hyperparameter (something developer sets) learning rate\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "torch.manual_seed(42)\n",
    "\n",
    "epochs = 200\n",
    "\n",
    "# Put data on target device\n",
    "X_train = X_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "X_test = X_test.to(device)\n",
    "y_test = y_test.to(device)\n",
    "\n",
    "# tracking model metrics\n",
    "epoch_count = []\n",
    "loss_values = []\n",
    "test_loss_values = []\n",
    "\n",
    "### Training\n",
    "for epoch in range(epochs):\n",
    "    # Set model to training mode\n",
    "    model_1.train() \n",
    "\n",
    "    # 1. Forward pass\n",
    "    y_pred = model_1(X_train)\n",
    "\n",
    "    # 2. calc loss\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "\n",
    "    # 3. Optimizer zero grad\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4. perform backprop\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. Step the optimizer\n",
    "    optimizer.step() \n",
    "\n",
    "    # Testing\n",
    "    model_1.eval() \n",
    "    with torch.inference_mode(): # turns off gradient tracking\n",
    "        # 1. forward pass\n",
    "        test_pred = model_1(X_test)\n",
    "\n",
    "        # 2. Calc loss\n",
    "        test_loss = loss_fn(test_pred, y_test)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        epoch_count.append(epoch)\n",
    "        loss_values.append(loss)\n",
    "        test_loss_values.append(test_loss)\n",
    "        print(f\"Epoch: {epoch} | train Loss: {loss} | Test loss: {test_loss}\")\n",
    "\n",
    "        # print model state\n",
    "        print(model_1.state_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction\n",
    "model_1.eval()\n",
    "with torch.inference_mode():\n",
    "    y_preds = model_1(X_test)\n",
    "\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(predictions=y_preds.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving PyTorch model\n",
    "from pathlib import Path\n",
    "\n",
    "# 1. Create models directory\n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 2.Create model save path\n",
    "MODEL_NAME = \"01_pytorch_workflow_model_1.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "# 3. Save model state dictionary\n",
    "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
    "torch.save(obj=model_1.state_dict(), f=MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Instantiate new model class\n",
    "load_model_1 = LinearRegressionModelWLayers()\n",
    "\n",
    "# 2. load saves state_dict\n",
    "load_model_1.load_state_dict(torch.load(f=MODEL_SAVE_PATH))\n",
    "\n",
    "load_model_1.to(device)\n",
    "\n",
    "load_model_1.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate loading model\n",
    "load_model_1.eval()\n",
    "with torch.inference_mode():\n",
    "    load_model_preds = load_model_1(X_test)\n",
    "\n",
    "y_preds == load_model_preds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
