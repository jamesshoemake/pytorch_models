{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. Neural Network classification with PyTorch\n",
    "\n",
    "Classification predicts what something is from a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Classification data\n",
    "from sklearn.datasets import make_circles\n",
    "\n",
    "# samples\n",
    "n_samples = 1000\n",
    "# create circles\n",
    "X, y = make_circles(n_samples, noise=0.03, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"first 5 samples of X:\\n {X[:5]}\")\n",
    "print(f\"first 5 samples of y:\\n {y[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dataframe\n",
    "import pandas as pd\n",
    "circles = pd.DataFrame({\"X1\": X[:, 0],\n",
    "                       \"X2\": X[:, 1],\n",
    "                       \"label\": y})\n",
    "circles.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(x=X[:, 0],\n",
    "            y=X[:,1],\n",
    "            c=y,\n",
    "            cmap=plt.cm.RdYlBu)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking import and output shapes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frist example of features and labels\n",
    "X_sample = X[0]\n",
    "y_sample = y[0]\n",
    "\n",
    "print(f\"Values for one sample of X: {X_sample} and y {y_sample}\")\n",
    "print(f\"Shapes for one sample of X: {X_sample.shape} and y {y_sample.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convernt data into tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.from_numpy(X).type(torch.float)\n",
    "y = torch.from_numpy(y).type(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:5], y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X), X.type, y.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building model\n",
    "\n",
    "1. Setup device agnositic code\n",
    "2. Construct model from nn.Module\n",
    "3. Define loss func and optimizers\n",
    "4. Create training and test loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. setup device agnostic code\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Construct model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. construct a model\n",
    "class CircleModelV0(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 2. 2 nn.linear layers\n",
    "        self.layer_1 = nn.Linear(in_features=2, out_features=5) # takes 2 features in, scales to 5 features\n",
    "        self.layer_2 = nn.Linear(in_features=5, out_features=1) # takes 5 features, classification to 1 (shape of y)\n",
    "\n",
    "\n",
    "    # 3. define a forward()\n",
    "    def forward(self, x):\n",
    "      return self.layer_2(self.layer_1(x))    # x -> layer 1 -> layer 2 -> output (classification)\n",
    "    \n",
    "# 4.instantiate an instance of model class and send it to the target device\n",
    "model_0 = CircleModelV0().to(device)\n",
    "model_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(model_0.parameters()).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.Sequential() can be used for similar models\n",
    "# model_0 = nn.Sequential(\n",
    "#     nn.Linear(in_features=2, out_features=5),\n",
    "#     nn.Linear(in_features=5, out_features=1)\n",
    "# ).to(device)\n",
    "# model_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "with torch.inference_mode():\n",
    "  untrained_preds = model_0(X_test.to(device))\n",
    "print(f\"Len of prediction: {len(untrained_preds)}, Shape: {untrained_preds.shape}\")\n",
    "print(f\"Len of test samples: {len(X_test)}, Shape: {X_test.shape}\")\n",
    "print(f\"\\n First 10 predictions:\\n{torch.round(untrained_preds[:10])}\")\n",
    "print(f\"\\n First 10 labelss:\\n{y_test[:10]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loss function and optimizer\n",
    "loss function\n",
    "* regression MAE or MSE (mean absolute err or mean squared err)  \n",
    "* classicification binary cross entropy or categorical cross entropy  \n",
    "\n",
    "optimizers\n",
    "* SGD\n",
    "* Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss() # sigmoid activation function included\n",
    "# optimizer\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(),\n",
    "                            lr=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = (correct/len(y_pred)) * 100\n",
    "    return acc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model\n",
    "\n",
    "1. forward pass\n",
    "2. calc loss\n",
    "3. optimize zero grad\n",
    "4. loss backward\n",
    "5. optimizer step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "model_0.eval()\n",
    "with torch.inference_mode():\n",
    "  y_logits = model_0(X_test.to(device))[:5]\n",
    "y_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid activiation function on model logits turns them into prediction probabilities\n",
    "# range-style round is preformed on prediction probabliy values \n",
    "y_pred_probs = torch.sigmoid(y_logits)\n",
    "y_pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find predicted labels\n",
    "y_preds = torch.round(y_pred_probs)\n",
    "\n",
    "# logits -> pred probs -> pred labels\n",
    "y_pred_labels = torch.round(torch.sigmoid(model_0(X_test.to(device))[:5]))\n",
    "\n",
    "# check equal\n",
    "print(torch.eq(y_preds.squeeze(), y_pred_labels.squeeze()))\n",
    "\n",
    "# get rid of the extra dimension\n",
    "y_preds.squeeze()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# building a train and test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model_0.train()\n",
    "\n",
    "    y_logits = model_0(X_train).squeeze()\n",
    "    y_preds = torch.round(torch.sigmoid(y_logits))\n",
    "\n",
    "    loss = loss_fn(y_logits,\n",
    "                   y_train)\n",
    "    \n",
    "    acc = accuracy_fn(y_true=y_train, \n",
    "                      y_pred=y_preds)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    model_0.eval()\n",
    "    with torch.inference_mode():\n",
    "        test_logits = model_0(X_test).squeeze()\n",
    "        test_pred = torch.round(torch.sigmoid(test_logits))\n",
    "\n",
    "        test_loss = loss_fn(test_logits,\n",
    "                            y_test)\n",
    "        \n",
    "        \n",
    "        test_acc = accuracy_fn(y_true=y_test,\n",
    "                               y_pred=test_pred)\n",
    "        \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch} | Loss: {loss:.5f}, Acc: {acc:.2f} | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make predictions and eval the model\n",
    "\n",
    "based on metric the model is not learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import plot_predictions, plot_decision_boundary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Train\")\n",
    "plot_decision_boundary(model_0, X_train, y_train)\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Test\")\n",
    "plot_decision_boundary(model_0, X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving a model\n",
    "\n",
    "Change the hyperparameters\n",
    "* add more layers - gives model more chances to learn patterns in the data\n",
    "* add more hidden units - go from 5 hidden to 10 hidden\n",
    "* Fit for longer - increase epochs\n",
    "* Change activation function\n",
    "* change learning rate\n",
    "* change loss function\n",
    "\n",
    "Attempt 1\n",
    "* add more hidden units: 5 -> 10\n",
    "* increase number of layers: 2 -> 3\n",
    "* increase number of epochs: 100 -> 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CircleModelV1(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.layer_1 = nn.Linear(in_features=2, out_features=10)\n",
    "        self.layer_2 = nn.Linear(in_features=10, out_features=10)\n",
    "        self.layer_3 = nn.Linear(in_features=10, out_features=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # z = self.layer_1(x)\n",
    "        # z = self.layer_2(z)\n",
    "        # z = self.layer_3(z)\n",
    "        return self.layer_3(self.layer_2(self.layer_1(x)))\n",
    "    \n",
    "model_1 = CircleModelV1().to(device)\n",
    "model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss() # sigmoid activation function included\n",
    "# optimizer\n",
    "optimizer = torch.optim.SGD(params=model_1.parameters(),\n",
    "                            lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "epochs = 1000\n",
    "\n",
    "X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model_1.train()\n",
    "\n",
    "    y_logits = model_1(X_train).squeeze()\n",
    "    y_preds = torch.round(torch.sigmoid(y_logits))\n",
    "\n",
    "    loss = loss_fn(y_logits,\n",
    "                   y_train)\n",
    "    \n",
    "    acc = accuracy_fn(y_true=y_train, \n",
    "                      y_pred=y_preds)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    model_1.eval()\n",
    "    with torch.inference_mode():\n",
    "        test_logits = model_1(X_test).squeeze()\n",
    "        test_pred = torch.round(torch.sigmoid(test_logits))\n",
    "\n",
    "        test_loss = loss_fn(test_logits,\n",
    "                            y_test)\n",
    "        \n",
    "        \n",
    "        test_acc = accuracy_fn(y_true=y_test,\n",
    "                               y_pred=test_pred)\n",
    "        \n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch: {epoch} | Loss: {loss:.5f}, Acc: {acc:.2f} | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}\")\n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Train\")\n",
    "plot_decision_boundary(model_1, X_train, y_train)\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Test\")\n",
    "plot_decision_boundary(model_1, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create linear data\n",
    "weight = 0.7\n",
    "bias = 0.3\n",
    "start = 0 \n",
    "end = 1\n",
    "step = 0.01\n",
    "\n",
    "X_regression = torch.arange(start,end,step).unsqueeze(dim=1)\n",
    "y_regression = weight * X_regression + bias\n",
    "\n",
    "print(len(X_regression))\n",
    "X_regression[:5], y_regression[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "train_split = int(0.8 * len(X_regression))\n",
    "X_train_regression, y_train_regression = X_regression[:train_split], y_regression[:train_split]\n",
    "X_test_regression, y_test_regression = X_regression[train_split:], y_regression[train_split:]\n",
    "\n",
    "# lengs\n",
    "len(X_train_regression), len(X_test_regression), len(y_train_regression), len(y_test_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(train_data=X_train_regression, train_labels=y_train_regression, \n",
    "                 test_data=X_test_regression, test_labels=y_test_regression)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = nn.Sequential(\n",
    "    nn.Linear(in_features=1, out_features=10),\n",
    "    nn.Linear(in_features=10, out_features=10),\n",
    "    nn.Linear(in_features=10, out_features=1)\n",
    ").to(device)\n",
    "model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "loss_fn = nn.L1Loss() # sigmoid activation function included\n",
    "# optimizer\n",
    "optimizer = torch.optim.SGD(params=model_2.parameters(),\n",
    "                            lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "epochs = 1000\n",
    "\n",
    "X_train_regression, y_train_regression = X_train_regression.to(device), y_train_regression.to(device)\n",
    "X_test_regression, y_test_regression = X_test_regression.to(device), y_test_regression.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model_2.train()\n",
    "    y_pred = model_2(X_train_regression)\n",
    "    loss = loss_fn(y_pred, y_train_regression)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    model_2.eval()\n",
    "    with torch.inference_mode():\n",
    "        test_pred = model_2(X_test_regression)\n",
    "        test_loss = loss_fn(test_pred, y_test_regression)\n",
    "        \n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch: {epoch} | Loss: {loss:.5f}| Test loss: {test_loss:.5f}\")\n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "model_2.eval()\n",
    "\n",
    "# predictions\n",
    "with torch.inference_mode():\n",
    "    y_pred = model_2(X_test_regression)\n",
    "\n",
    "# plots\n",
    "plot_predictions(train_data=X_train_regression.cpu(), \n",
    "                 train_labels=y_train_regression.cpu(),\n",
    "                 test_data=X_test_regression.cpu(),\n",
    "                 test_labels=y_test_regression.cpu(),\n",
    "                 predictions=y_pred.cpu())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# non-linearity\n",
    "* paterns drawn with striaght and non-straight lines\n",
    "* linear and non-linear functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a plot new data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_circles\n",
    "\n",
    "n_samples = 1000\n",
    "\n",
    "X, y = make_circles(n_samples=n_samples,\n",
    "                    noise=0.03,\n",
    "                    random_state=42)\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.RdYlBu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# data to tensor\n",
    "X = torch.from_numpy(X).type(torch.float)\n",
    "y = torch.from_numpy(y).type(torch.float)\n",
    "\n",
    "# split train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "\n",
    "X_test[:5], y_train[:5]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model with non-linearity\n",
    "\n",
    "* Linear = straight lines\n",
    "* Non-linear = non-straight (curves)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with non-linear activations \n",
    "from torch import nn\n",
    "\n",
    "class CircleModelV2(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.layer_1 = nn.Linear(in_features=2, out_features=10)\n",
    "        self.layer_2 = nn.Linear(in_features=10, out_features=10)\n",
    "        self.layer_3 = nn.Linear(in_features=10, out_features=1)\n",
    "        self.relu = nn.ReLU() # non-linear activaction function\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.layer_3(self.relu(self.layer_2(self.relu(self.layer_1(x)))))\n",
    "\n",
    "model_3 = CircleModelV2().to(device)\n",
    "model_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss() # sigmoid activation function included\n",
    "# optimizer\n",
    "optimizer = torch.optim.SGD(params=model_3.parameters(),\n",
    "                            lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "\n",
    "X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "X_test, y_test = X_test.to(device), y_test.to(device) \n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model_3.train()\n",
    "    y_logits = model_3(X_train).squeeze()\n",
    "    y_preds = torch.round(torch.sigmoid(y_logits))\n",
    "    loss = loss_fn(y_logits, y_train)\n",
    "    acc = accuracy_fn(y_true=y_train, y_pred=y_preds)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    model_3.eval()\n",
    "    with torch.inference_mode():\n",
    "        test_logits = model_3(X_test).squeeze()\n",
    "        test_pred = torch.round(torch.sigmoid(test_logits))\n",
    "        test_loss = loss_fn(test_logits, y_test)\n",
    "        test_acc = accuracy_fn(y_true=y_test, y_pred=test_pred)\n",
    "        \n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch: {epoch} | Loss: {loss:.5f}, Acc: {acc:.2f} | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.eval()\n",
    "with torch.inference_mode():\n",
    "    y_preds = torch.round(torch.sigmoid(model_3(X_test))).squeeze()\n",
    "y_preds[:10], y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visual evaluation\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Train\")\n",
    "plot_decision_boundary(model_3, X_train, y_train)\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Test\")\n",
    "plot_decision_boundary(model_3, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
