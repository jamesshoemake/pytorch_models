{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = {\n",
    "    1: \"data (prepare and load)\",\n",
    "    2: \"build model\",\n",
    "    3: \"fitting the model to data (training)\",\n",
    "    4: \"making predictions and evaluating a model (inference)\",\n",
    "    5: \"saving and loading a model\",\n",
    "    6: \"putting it all together\"\n",
    "}\n",
    "workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn # nn contain all of PT building blocks\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Py version\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.version.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data (preparing and loading)\n",
    "\n",
    "1. Get data into numerical representation\n",
    "2. Build a model to learn patterns in the numerical representation\n",
    "\n",
    "Create known data using linear regression formula  \n",
    "linear regression formula creates a straight line with known parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create *known* parameters\n",
    "weight = 0.7\n",
    "bias = 0.3 \n",
    "\n",
    "# create range\n",
    "start = 0\n",
    "end = 1\n",
    "step = 0.02\n",
    "X = torch.arange(start, end, step).unsqueeze(dim=1)\n",
    "y = weight * X + bias\n",
    "\n",
    "X[:10], y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X), len(y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train/test split\n",
    "train_split = int(0.8 * len(X))\n",
    "X_train, y_train = X[:train_split], y[:train_split]\n",
    "X_test, y_test = X[train_split:], y[train_split:]\n",
    "\n",
    "len(X_train), len(y_train), len(X_test), len(y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(train_data=X_train,\n",
    "                     train_labels=y_train,\n",
    "                     test_data=X_test,\n",
    "                     test_labels=y_test,\n",
    "                     predictions=None):\n",
    "    \"\"\"\n",
    "    Plots training data, test data and compares predictions.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10,7))\n",
    "\n",
    "    # Plot training data in blue\n",
    "    plt.scatter(train_data, train_labels, c=\"b\", s=4, label=\"Training data\")\n",
    "\n",
    "    # Plot test data in green\n",
    "    plt.scatter(test_data, test_labels, c=\"g\", s=4, label=\"Testing data\")\n",
    "\n",
    "    # if predictions\n",
    "    if predictions is not None:\n",
    "        # Plot the predictions if they exist\n",
    "        plt.scatter(test_data, predictions, c=\"r\", s=4, label=\"Predictions\")\n",
    "    \n",
    "    plt.legend(prop={\"size\": 14});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build model\n",
    "\n",
    "model explanation:\n",
    "* starts with random values (weight & bias)\n",
    "* look at training data and adjust the random values to better represent the ideal values\n",
    "* accomplished through 2 algos:\n",
    "    1. Gradient descent\n",
    "    2. Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression model\n",
    "# most things in PyTorch inherit from nn.Module\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(1, # start with random value\n",
    "                                                requires_grad=True, # update via gradient descent\n",
    "                                                dtype=torch.float)) \n",
    "        self.bias = nn.Parameter(torch.randn(1,\n",
    "                                              requires_grad=True,\n",
    "                                              dtype=torch.float))\n",
    "        \n",
    "    # forward method to define the computation in model\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.weights * x + self.bias # linear regression formula \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch model building essentials\n",
    "\n",
    "* torch.nn - contains building blocks for computational graphs\n",
    "* torch.nn.Parameter - what parameters should the model try to learn, often a PT layer from torch.nn will set these\n",
    "* torch.nn.Module - base clas for nn modules, if subclassed always override the foward method\n",
    "* torch.optim - is where to find the optimizers for gradient descent\n",
    "* def forward() - all nn.Module subclasses require this to be overriden, defines what happens in the forward computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### checking contents of the PyTorch model\n",
    "# .parameters() displays the parameters for the model\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# instance of model (subclass of nn.Module)\n",
    "model_0 = LinearRegressionModel()\n",
    "\n",
    "# see parameters\n",
    "list(model_0.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0.state_dict()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make predictions using torch.inference_mode()\n",
    "data passed through model goes through forward method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions with model\n",
    "with torch.inference_mode():\n",
    "    y_preds = model_0(X_test)\n",
    "\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(predictions=y_preds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training model\n",
    "\n",
    "idea behind a model is to move from unknown parameters to some know parameters\n",
    "\n",
    "loss \n",
    "\n",
    "This needed to train:\n",
    "- *loss* (criterion, cost) function  can help measuring how wrong a model's predictions are.\n",
    "- *Optimizer* - account for loss of model and adjust model parameters to improve the loss function\n",
    "  \n",
    "PyTorch:\n",
    "- training loop\n",
    "- test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup loss function\n",
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "# Setup optimizer\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(),\n",
    "                            lr=0.01 # hyperparameter (something developer sets) learning rate\n",
    "                            )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### building a training (and testing) loop in PyTorch\n",
    "\n",
    "Need:\n",
    "0. Loop data\n",
    "1. Forward pass (data moving through the model's forward()) to make predictions  - aka forward propagation\n",
    "2. Calculate the loss (compare forward pass to ground truth labels)\n",
    "3. Loss backward (***backpropagation***) - move backwards to calcualte the gradients of the parameters with respect to the loss\n",
    "4. Optimizers -  use the optimizer to adjust the model's parametes attempting to improve the loss (***gradient descent**) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "# epoch (hyperparameter) is one loop through the data\n",
    "epochs = 200\n",
    "\n",
    "# tracking model metrics\n",
    "epoch_count = []\n",
    "loss_values = []\n",
    "test_loss_values = []\n",
    "\n",
    "### Training\n",
    "# 0. loop through data\n",
    "for epoch in range(epochs):\n",
    "    # Set model to training mode\n",
    "    model_0.train() # train mode in PyTorch sets all parameters which require gradients to require gradients\n",
    "\n",
    "    # 1. Forward pass\n",
    "    y_pred = model_0(X_train)\n",
    "\n",
    "    # 2. calc loss\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "\n",
    "    # 3. Optimizer zero grad\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4. perform backpop on loss with repsec tot parameters of model\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. Step the optimizer (perform gradient descent)\n",
    "    optimizer.step() # by default how the optimizers changes will acculumate through the loop, re zeroes for step 3 of the next loop\n",
    "\n",
    "    # Testing\n",
    "    model_0.eval() # turns off settings not needed for evaluation (dropout, batch norm)\n",
    "    with torch.inference_mode(): # turns off gradient tracking\n",
    "        # 1. forward pass\n",
    "        test_pred = model_0(X_test)\n",
    "\n",
    "        # 2. Calc loss\n",
    "        test_loss = loss_fn(test_pred, y_test)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        epoch_count.append(epoch)\n",
    "        loss_values.append(loss)\n",
    "        test_loss_values.append(test_loss)\n",
    "        print(f\"Epoch: {epoch} | MAE Train Loss: {loss} | MAE Test loss: {test_loss}\")\n",
    "\n",
    "        # print model state\n",
    "        print(model_0.state_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "plt.plot(epoch_count, np.array(torch.tensor(loss_values).cpu().numpy()), label=\"Train loss\")\n",
    "plt.plot(epoch_count, test_loss_values, label=\"Test loss\")\n",
    "plt.title(\"Training and test loss curves\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.ylabel(\"Epochs\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print model state\n",
    "print(model_0.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    y_preds_new = model_0(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(predictions=y_preds_new)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving a model in PyTorch\n",
    "\n",
    "Three main methods\n",
    "1. `torch.save()` - saves model in python pickle\n",
    "2. `torch.load()` - loads saved model\n",
    "3. `torch.nn.Module.load_state_dict()` - loads model's saved state dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving PyTorch model\n",
    "from pathlib import Path\n",
    "\n",
    "# 1. Create models directory\n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 2.Create model save path\n",
    "MODEL_NAME = \"01_pytorch_workflow_model_0.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "# 3. Save model state dictionary\n",
    "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
    "torch.save(obj=model_0.state_dict(), f=MODEL_SAVE_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading PyTorch model\n",
    "when saving a state_dict() -> a new model class instance is loaded with the saved state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Instantiate new model class\n",
    "load_model_0 = LinearRegressionModel()\n",
    "\n",
    "# 2. load saves state_dict\n",
    "load_model_0.load_state_dict(torch.load(f=MODEL_SAVE_PATH))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model_0.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction\n",
    "load_model_0.eval()\n",
    "with torch.inference_mode():\n",
    "    load_model_preds = load_model_0(X_test)\n",
    "\n",
    "load_model_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0.eval()\n",
    "with torch.inference_mode():\n",
    "    y_preds = model_0(X_test)\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Compare models\n",
    "y_preds == load_model_preds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
